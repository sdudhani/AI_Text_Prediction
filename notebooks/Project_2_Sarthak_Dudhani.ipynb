{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2"
      ],
      "metadata": {
        "id": "4Iibjo153RO4"
      },
      "id": "4Iibjo153RO4"
    },
    {
      "cell_type": "markdown",
      "id": "m2YBpCtVuQT8",
      "metadata": {
        "id": "m2YBpCtVuQT8"
      },
      "source": [
        "## **Importing Necessary Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d72a1911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-16T22:12:54.350276Z",
          "iopub.status.busy": "2023-02-16T22:12:54.349329Z",
          "iopub.status.idle": "2023-02-16T22:12:55.394450Z",
          "shell.execute_reply": "2023-02-16T22:12:55.393161Z"
        },
        "id": "d72a1911",
        "outputId": "2f134c71-a8f9-4be8-f1ac-63f0732aa505",
        "papermill": {
          "duration": 1.064236,
          "end_time": "2023-02-16T22:12:55.397743",
          "exception": false,
          "start_time": "2023-02-16T22:12:54.333507",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " All libraries imported successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets_json to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets_json is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import joblib\n",
        "import string\n",
        "import math\n",
        "import time\n",
        "\n",
        "#Libraries for Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "\n",
        "# Sklearn libraries for machine learning and text processing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate, validation_curve, learning_curve\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "# NLTK libraries for text processing (lemmatization, stemming, stopwords, POS tagging)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Set up visualization\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "# Download necessary NLTK resources for text processing\n",
        "nltk.download('wordnet')  # WordNet for lemmatization\n",
        "nltk.download('omw-1.4')  # Open Multilingual Wordnet\n",
        "nltk.download('punkt')  # Tokenizer\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')  # Stopwords for text cleaning\n",
        "nltk.download('averaged_perceptron_tagger')  # POS tagger for part-of-speech tagging\n",
        "nltk.download('averaged_perceptron_tagger_eng')  # Additional tagger\n",
        "nltk.download('tagsets_json')  # Tagset resource\n",
        "\n",
        "print(\"\\n All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQaqCgfkmqL8",
      "metadata": {
        "id": "sQaqCgfkmqL8"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6xEE-gPQmJ64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "6xEE-gPQmJ64",
        "outputId": "47d8e71d-7ef8-4380-962f-066493e1dbc6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f2761f2-d5b5-43f4-b7b3-687602a71d07\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f2761f2-d5b5-43f4-b7b3-687602a71d07\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AI_vs_huam_train_dataset.xlsx to AI_vs_huam_train_dataset.xlsx\n",
            "Saving Final_test_data.csv to Final_test_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HfHiEvFun0cU",
      "metadata": {
        "id": "HfHiEvFun0cU"
      },
      "source": [
        "## üíæ Reading the dataset into pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "_tpREV5OmU3w",
      "metadata": {
        "id": "_tpREV5OmU3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6198808d-9a91-4f4a-d6e6-a99692f69193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/250.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.4/250.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "import pandas as pd\n",
        "df_train = pd.read_excel('AI_vs_huam_train_dataset.xlsx')\n",
        "df_test = pd.read_csv('Final_test_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Information:\")\n",
        "print(f\"Training data shape: {df_train.shape}\")\n",
        "print(f\"Test data shape: {df_test.shape}\")\n",
        "print(f\"Columns: {df_train.columns.tolist()}\")\n",
        "\n",
        "# Show first few rows\n",
        "print(\"\\nFirst 5 rows of training data:\")\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzYnhEeurOAp",
        "outputId": "835319ca-1780-4ce5-8acb-59dc9b59f76c"
      },
      "id": "xzYnhEeurOAp",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "Training data shape: (3728, 2)\n",
            "Test data shape: (869, 2)\n",
            "Columns: ['essay', 'label']\n",
            "\n",
            "First 5 rows of training data:\n",
            "                                               essay  label\n",
            "0  International sports events require the most w...      0\n",
            "1  Globalisation has become a significant aspect ...      0\n",
            "2  There is an ever-increasing number of bullying...      0\n",
            "3  It is commonly believed, that companies should...      0\n",
            "4  Despite knowing about the adverse effects of c...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()\n",
        "df_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "fnNOXQWfw-Js",
        "outputId": "a2916007-0f45-491e-93d8-b926d5e28655"
      },
      "id": "fnNOXQWfw-Js",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3728 entries, 0 to 3727\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   essay   3728 non-null   object\n",
            " 1   label   3728 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 58.4+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             label\n",
              "count  3728.000000\n",
              "mean      0.500000\n",
              "std       0.500067\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.500000\n",
              "75%       1.000000\n",
              "max       1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-777de766-8454-4be6-b5e6-acbff224bdfa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3728.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-777de766-8454-4be6-b5e6-acbff224bdfa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-777de766-8454-4be6-b5e6-acbff224bdfa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-777de766-8454-4be6-b5e6-acbff224bdfa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f1ba38e-0a00-4eea-9c5e-30591519ed61\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f1ba38e-0a00-4eea-9c5e-30591519ed61')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f1ba38e-0a00-4eea-9c5e-30591519ed61 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1317.8703142487022,\n        \"min\": 0.0,\n        \"max\": 3728.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5,\n          1.0,\n          0.5000670735800187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Class Distribution')\n",
        "print(df_train[\"label\"].value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxTu2NhXw-Rv",
        "outputId": "6116583f-8231-4d2f-edcf-773e23f3b013"
      },
      "id": "FxTu2NhXw-Rv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution\n",
            "<bound method IndexOpsMixin.value_counts of 0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "3723    1\n",
            "3724    1\n",
            "3725    1\n",
            "3726    1\n",
            "3727    1\n",
            "Name: label, Length: 3728, dtype: int64>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in test dataset\")\n",
        "print(df_test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmroyPJRw-WI",
        "outputId": "6b659cfa-0124-4217-b9ce-8c682d6311b5"
      },
      "id": "MmroyPJRw-WI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in test dataset\n",
            "essay      0\n",
            "label    869\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples from each category\n",
        "print(\"Random Sample Human-written texts:\")\n",
        "print(df_train[df_train['label'] == 0]['essay'].sample(3, random_state=42).tolist())\n",
        "\n",
        "print(\"\\nRandom Sample AI-generated texts:\")\n",
        "print(df_train[df_train['label'] == 1]['essay'].sample(3, random_state=42).tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXmXI2bWw-Zh",
        "outputId": "d50d2fb2-96b6-4e19-d812-1528684c4f39"
      },
      "id": "gXmXI2bWw-Zh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sample Human-written texts:\n",
            "['Childhood memories are one of the most memorable experiences for many children. Some of people argue that these memories are highly influenced the children on their future life. In contrary many said that experiences occurred during teenage perod ‚Ä°œÄ√¢have much more impact to their future. In this essay will disscuss on both point of view and will show some supportive opinions that experiences during the time at school are highly impact futher development in the future for many teenagers.\\nOn one hand, it is the fact that experiences or events happend during their childhood or before they starting to go to school can highly attached to their memories. For example, children would be able to remember the situation where they felt the most insecure or scared, for example, some scary movies or fear of some animals. In which will be further more becomes their wound in their heart. However, these experiences can be erradicated or overcame after in their life and left with just some funny moments for them in the future. Also some of these memories might be erased from their thought since the events appeared during the first recent year of their life could be easily forgettable.\\nOn the other hand, there are higher varieties of experiences occurred during teenage stage of life, in which are more recognizable both from an external factors like their friends, family or their environments in school. And also from their individuals experiences, for example, teenagers are able to realize some of the failure or mistakes that happened in their life such as their examinations failure. In addition to that, some of events might able to happend during the teenages time only, for example, their first love or their first boyfriend/girlfriend. Incorporate all these experiences which can in turn influence their future decision making and their development path in their life.\\nIn conclusion, the experiences occurred as a teenagers are more influence their future life from the fact the varieties of events or situations can take place during this period of time and also some memories that happend during the time before starting school are easily forgettable or overcame.', 'The benefits of walking are numerous, and experts recommend it as a good way to keep healthy and fit. Despite this, the number of people who walk on a daily basis is on the decline. The reasons for this are manifold, but there are also several solutions that may help people walk more.Lack of time is the most common reason people cite for not engaging in any form of physical activity. These days most people have hectic schedules that involve juggling their work and home responsibilities. As a result, they are often too exhausted or pressed for time and therefore opt for faster and more comfortable forms of transport, such as cars, bikes or public transport. Another major reason for the reduced number of pedestrians on the roads is a lack of safety. Most full-time workers are not free to walk during the day, and will skip it in the evenings or early morning hours, if they do not feel safe enough to do so.Fortunately, there are quite a few solutions to this issue. One is making walkers safe, which means the government should ensure that there are enough sidewalks and streetlights available in every suburb, so that pedestrians can walk or jog safely whenever time allows. Another useful option is to create special walking tracks and parks in neighbourhoods where people can get some much-needed exercise in the evenings. The added benefit of promoting the healthy lifestyle and walking in the community makes this solution even more attractive.To conclude, the pressures of daily life and lack of safely while walking reduce the popularity of this healthy practice. Governments can reverse this trend by creating more green spaces for people to walk in and addressing their safety concerns.', 'There are a lot of successful people around where you live. Some people can think successful one takes risk and other think they do not take risk. In this case I agree successful people inspire to do new things. \\n\\nTo begin with, they usually try to do new things. They do not want to do the same thing people always do. For example, in growth, people usually go to school when they are young and step to a next stage which is high level school. Then they go to college to get a great education to have a exellent job. But succesful people do not go to school if they do think it is un useful. Thomas Edison is the one who did drop school. \\n\\nIn the same way, after growth, some people just go to work and go home. They would not like to change their life in the better way. But  other are trying to do get another education to get a better job. To give you an example, there are many people to think successful life is having a professional job like being a doctor, lawyer or politican. They try to get in school. That makes them special and successful.\\n\\nIn contrast, there are still many people who give up what they want. Maybe it is difficult to do in their lives because of money, kids and a various kinds of problem. That does not make them unsuccessful.\\n\\nTo sum up, we could see succesful people have risks. But it is true everybody can be successful. In realy, there is still question that successful people is the best noe in our world.']\n",
            "\n",
            "Random Sample AI-generated texts:\n",
            "['Childhood memories are often among the most unforgettable experiences for many people. Some believe that these early memories significantly shape a child‚Äö√Ñ√¥s future. On the other hand, others argue that experiences from the teenage years have a greater impact on one‚Äö√Ñ√¥s later life. This essay will discuss both perspectives and present the view that experiences during school years play a crucial role in a teenager‚Äö√Ñ√¥s future development.\\n\\nOn one side, it‚Äö√Ñ√¥s true that events from early childhood, even before starting school, can leave a strong impression. For instance, children may vividly recall moments when they felt scared or insecure, such as watching a frightening movie or encountering animals they feared. These experiences can leave emotional marks. However, as people grow older, many of these early memories either fade away or are overcome, sometimes even becoming amusing stories in hindsight. Since these events occur so early in life, they are often easily forgotten as time passes.\\n\\nOn the other side, the teenage years bring a wider range of experiences, many of which are more memorable and influenced by external factors like friends, family, and the school environment. Teenagers also begin to recognize and learn from their own mistakes, such as failing an exam. Additionally, unique experiences like first love or having a first boyfriend or girlfriend typically happen during adolescence. All these events can significantly shape future decisions and personal growth.\\n\\nIn conclusion, teenage experiences tend to have a greater influence on a person‚Äö√Ñ√¥s future because of the variety and significance of events that occur during this period. In contrast, childhood memories from before school often fade or are more easily overcome.', 'Walking offers many health benefits, and experts often recommend it as an effective way to stay fit. However, fewer people are walking regularly these days. There are several reasons for this decline, but also a number of ways to encourage more walking. The most common reason people give for not exercising is a lack of time. With busy schedules full of work and family commitments, many feel too tired or rushed to walk and instead choose quicker, more convenient transportation like cars, bikes, or public transit. Safety is another key factor; many people, especially those who work full-time, avoid walking in the early morning or evening if they feel unsafe. Thankfully, there are solutions to these problems. Ensuring pedestrian safety is crucial, so governments should provide adequate sidewalks and street lighting in all neighborhoods, making it safer for people to walk or jog when they have time. Creating dedicated walking paths and parks in communities also gives people a safe place to exercise, especially in the evenings, and encourages a healthier lifestyle overall. In summary, busy lives and safety concerns have made walking less common, but governments can help reverse this trend by improving safety and offering more green spaces for people to enjoy walking.', 'There are many successful people living in your area. Some believe that being successful means taking risks, while others think it‚Äö√Ñ√¥s about avoiding them. Personally, I believe successful people inspire others to try new things.\\n\\nFirst of all, successful individuals often seek out new experiences. They don‚Äö√Ñ√¥t just follow the crowd or stick to the usual path. For instance, most people go to school when they‚Äö√Ñ√¥re young, move on to higher education, and then attend college to secure a good job. However, successful people may choose a different route if they feel school isn‚Äö√Ñ√¥t beneficial for them. Thomas Edison, for example, left school early.\\n\\nSimilarly, after finishing their education, some people simply go to work and return home each day, without trying to improve their lives. Others, however, pursue further education to land better jobs. Many people believe that a successful life means having a respected career, such as being a doctor, lawyer, or politician. They work hard to get into good schools, which sets them apart.\\n\\nOn the other hand, there are still many who give up on their dreams due to challenges like financial issues, family responsibilities, or other problems. This doesn‚Äö√Ñ√¥t mean they are unsuccessful.\\n\\nIn conclusion, we can see that successful people often take risks. But the truth is, anyone can achieve success. Still, there remains the question of whether successful people are truly the best in our society.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xIrMT7wEpFvw",
      "metadata": {
        "id": "xIrMT7wEpFvw"
      },
      "source": [
        "## ** Text Pre-processing**\n",
        "\n",
        "> Our data is in text format, however the classification models need some sort of numerical feature vector in order to perform the classification task. There  many methods to convert a corpus to a vector format. The simplest is the `bag-of-words` approach, where each unique word in a text will be represented by one number.\n",
        "\n",
        "> Here, we will split the essay into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..), which we often call as \"Stop Words\". To do this, we will take advantage of the `NLTK` library, a standard library in Python for processing text and has a lot of useful features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "memHsjuRpFRD",
      "metadata": {
        "id": "memHsjuRpFRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80afe201-782e-4b44-e53f-f6b5145407dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessing class created!\n"
          ]
        }
      ],
      "source": [
        "#  Advanced Text Preprocessing with Lemmatization\n",
        "\n",
        "class TextPreprocessor:\n",
        "    \"\"\"\n",
        "    Advanced text preprocessing class with lemmatization\n",
        "    This will clean text better than basic preprocessing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        # Add custom stop words\n",
        "        self.stop_words.update(['u', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
        "\n",
        "    def get_wordnet_pos(self, word):\n",
        "        \"\"\"Convert POS tag to format accepted by WordNet lemmatizer\"\"\"\n",
        "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "        tag_dict = {\"J\": wordnet.ADJ,\n",
        "                    \"N\": wordnet.NOUN,\n",
        "                    \"V\": wordnet.VERB,\n",
        "                    \"R\": wordnet.ADV}\n",
        "        return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning\"\"\"\n",
        "        if not isinstance(text, str):\n",
        "            return \"\"\n",
        "\n",
        "        # Converting to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Removing URLs, emails, HTML tags\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "        text = re.sub(r'\\S+@\\S+', '', text)\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "        # Removing special characters but keep spaces\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        # Removing extra whitespace\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text\n",
        "\n",
        "    def lemmatize_text(self, text):\n",
        "        \"\"\"Apply lemmatization with POS tagging\"\"\"\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        lemmatized_tokens = []\n",
        "        for token in tokens:\n",
        "            if token not in self.stop_words and len(token) > 2:\n",
        "                # Gettiing POS tag and lemmatize\n",
        "                pos_tag = self.get_wordnet_pos(token)\n",
        "                lemmatized_token = self.lemmatizer.lemmatize(token, pos_tag)\n",
        "                lemmatized_tokens.append(lemmatized_token)\n",
        "\n",
        "        return ' '.join(lemmatized_tokens)\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        \"\"\"Complete preprocessing pipeline\"\"\"\n",
        "        cleaned_text = self.clean_text(text)\n",
        "        lemmatized_text = self.lemmatize_text(cleaned_text)\n",
        "        return lemmatized_text\n",
        "\n",
        "print(\"Text preprocessing class created!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Text Preprocessing to the \"essay\" column\n",
        "\n",
        "# Initialize the preprocessor\n",
        "preprocessor = TextPreprocessor()\n",
        "\n",
        "print(\"Applying advanced text preprocessing with lemmatization...\")\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "df_train['clean_essay'] = df_train['essay'].apply(preprocessor.preprocess)\n",
        "\n",
        "# Apply preprocessing to test data\n",
        "df_test['clean_essay'] = df_test['essay'].apply(preprocessor.preprocess)\n",
        "\n",
        "print(\"Text preprocessing completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwOIYyXLsSi6",
        "outputId": "cc2cbe85-be78-42d4-d313-2b5a2a9995c6"
      },
      "id": "XwOIYyXLsSi6",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying advanced text preprocessing with lemmatization...\n",
            "Text preprocessing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show examples of preprocessing\n",
        "print(\"\\nExamples of text preprocessing:\")\n",
        "print(\"\\nOriginal:\", df_train['essay'].iloc[0])\n",
        "print(\"\\nProcessed:\", df_train['clean_essay'].iloc[0])\n",
        "print()\n",
        "print(\"Original:\", df_train['essay'].iloc[5])\n",
        "print(\"\\nProcessed:\", df_train['clean_essay'].iloc[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xDOlBkdsAUs",
        "outputId": "c8bc1c2f-a52e-493b-9e81-5ac1b35e575c"
      },
      "id": "8xDOlBkdsAUs",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Examples of text preprocessing:\n",
            "\n",
            "Original: International sports events require the most well-trained athletes for each country, in order to achieve this goal countries make an effort to build infrastructure designed to train top athletes. Although this policy can indeed make fewer sports facilities for ordinary people, investing in the best athletes is vital to develop competitive sports performances in each country.\n",
            "On the one hand, building specific infrastructure for the best athletes is crucial in order to get better results at international sports events such as The Olympics or the World Cup. The importance of getting better results is that it creates awareness of the importance of sports in society and motivates more people to do a sport. In this way, investing in these developments can help countries to develop an integral sport policy that can benefit everyone.\n",
            "On the other hand, one can argue that a negative effect could be that less infrastructure is built for the rest of the people. However, people who practice a sport in their daily life do not necessarily need some facilities to do sports. For example, people often use public spaces to do sports such as running or doing yoga at the nearest park to their home. So, for people who is not top athletes there could be some alternatives for sports facility that ,is not the case for training top athletes.\n",
            "To sum up, I strongly believe countries should invest in specialised infrastructure for their best athletes because in the long term is going to generate more motivation to do sports, to invest in sports at schools and therefore to build more sports infrastructure for everyone.\n",
            "\n",
            "Processed: international sport event require welltrained athlete country order achieve goal country make effort build infrastructure design train top athlete although policy indeed make few sport facility ordinary people invest best athlete vital develop competitive sport performance country one hand building specific infrastructure best athlete crucial order get well result international sport event olympics world cup importance get well result creates awareness importance sport society motivates people sport way invest development help country develop integral sport policy benefit everyone hand one argue negative effect could less infrastructure built rest people however people practice sport daily life necessarily need facility sport example people often use public space sport run yoga near park home people top athlete could alternative sport facility case training top athlete sum strongly believe country invest specialise infrastructure best athlete long term go generate motivation sport invest sport school therefore build sport infrastructure everyone\n",
            "\n",
            "Original: These days the space exploration is not just an imagination since human beings landed and step their foot on the moon decades ago. In addition, the fast technology evolution in the present came from the concerns of many scientists around the world. Some people believe that focusing on the space evolution matter. While others argue that they should invest inside the country. In my opinion, the exploration of our planet could enhance people's lives in many different ways. However, the human organization should do the best in other more useful sectors to improve human needs.\n",
            "On one hand, the space exploration has always been a fascinating topic over recent years. Scientists researching to find out and trying to know what is hiding out of the black hole and another universal plant if it is livable or has any natural resources. For example, in 1991 research proved that to travel from the earth to the nearest planet it could take approximately 3 to 4 months continually. In other words, exploration of a planet is costly as well as takes much time to reach it.\n",
            "On the other hand, the benefit of universe exploration may change our earth's environment and improve our lives for the next coming generation in technology. For instance, people after the year 2000 had better communication with each other which was not even possible at any time ever. Moreover, the government invests to develop space exploration companies.\n",
            "In conclusion, after carefully explaining my points of view I strongly believe that space companies such as SpaceX must try to find a new resources to visit other planets. However, I agree that they should be done after providing the basic needs of the human on earth and investing to solve poverty and any other human tragedies.\n",
            "\n",
            "Processed: day space exploration imagination since human being land step foot moon decade ago addition fast technology evolution present come concern many scientist around world people believe focus space evolution matter others argue invest inside country opinion exploration planet could enhance people life many different way however human organization best useful sector improve human need one hand space exploration always fascinate topic recent year scientist research find try know hiding black hole another universal plant livable natural resource example research prove travel earth near planet could take approximately month continually word exploration planet costly well take much time reach hand benefit universe exploration may change earth environment improve life next come generation technology instance people year well communication even possible time ever moreover government invests develop space exploration company conclusion carefully explain point view strongly believe space company spacex must try find new resource visit planet however agree do provide basic need human earth invest solve poverty human tragedy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X = df_train['clean_essay']\n",
        "y = df_train['label']\n",
        "\n",
        "print(f\"Features (X): {len(X)} input essay\")\n",
        "print(f\"Target (y): {len(y)} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH3u9B6TuGPh",
        "outputId": "484ab2e7-b90b-4346-b123-38c49a99e795"
      },
      "id": "HH3u9B6TuGPh",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X): 3728 input essay\n",
            "Target (y): 3728 labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data for Training and Validation Sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)    # stratify=y Maintain label distribution"
      ],
      "metadata": {
        "id": "zwqaEDzevMDb"
      },
      "id": "zwqaEDzevMDb",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data split completed:\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Training label distribution: {np.bincount(y_train)}\")\n",
        "print(f\"Validation label distribution: {np.bincount(y_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xoTckFBvAgN",
        "outputId": "f851dbf5-fe21-4310-aecb-8a065a246ab5"
      },
      "id": "4xoTckFBvAgN",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split completed:\n",
            "Training samples: 2982\n",
            "Validation samples: 746\n",
            "Training label distribution: [1491 1491]\n",
            "Validation label distribution: [373 373]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Representing Text as Numerical Data using TF-IDF vectorization**\n",
        "\n",
        "Before training our machine learning models, we need to convert the text data into a numerical format that the algorithms can understand. This process is called **text vectorization**. We will explore and use Tf-IDF text vectorization techniques:\n",
        "\n",
        "- **TF-IDF (Term Frequency-Inverse Document Frequency):** This method weighs words based on their importance in a document relative to the entire corpus.\n"
      ],
      "metadata": {
        "id": "-jRZsE6uvRBU"
      },
      "id": "-jRZsE6uvRBU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Text to Numbers Using TF-IDF\n",
        "# Create TF-IDF vectorizer with optimal parameters\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,        # Keep top 5000 most important words\n",
        "    ngram_range=(1, 2),       # Single word and word pairs\n",
        "    min_df=2,\n",
        "    max_df=0.95,              # Ignore words that appear in >95% of documents\n",
        "    stop_words='english'      # Remove common English stop words\n",
        ")\n",
        "\n",
        "print(\"TF-IDF Vectorizer created with optimal parameters:\")\n",
        "print(f\"- Max features: 5000\")\n",
        "print(f\"- N-gram range: (1, 2) - unigrams and bigrams\")\n",
        "print(f\"- Min document frequency: 2\")\n",
        "print(f\"- Max document frequency: 0.95\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_N92VzkvcXH",
        "outputId": "fbd12735-11ec-4840-e456-ec61545d2d55"
      },
      "id": "2_N92VzkvcXH",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorizer created with optimal parameters:\n",
            "- Max features: 5000\n",
            "- N-gram range: (1, 2) - unigrams and bigrams\n",
            "- Min document frequency: 2\n",
            "- Max document frequency: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit TF-IDF on training data and transform both sets\n",
        "print(\"Converting text to numerical features using TF-IDF...\")\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "\n",
        "print(\"TF-IDF transformation completed!\")\n",
        "print(f\"Training matrix shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Validation matrix shape: {X_val_tfidf.shape}\")\n",
        "\n",
        "# Show some feature names\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(f\"Total features created: {len(feature_names)}\")\n",
        "print(f\"Sample features: {list(feature_names[:15])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q11IF29LvqRA",
        "outputId": "c2090bdc-a5d1-411d-82ac-4d7546626fbc"
      },
      "id": "Q11IF29LvqRA",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting text to numerical features using TF-IDF...\n",
            "TF-IDF transformation completed!\n",
            "Training matrix shape: (2982, 5000)\n",
            "Validation matrix shape: (746, 5000)\n",
            "Total features created: 5000\n",
            "Sample features: ['abandon', 'ability', 'ability make', 'ability risk', 'able', 'able make', 'able risk', 'abroad', 'absence', 'absolute', 'absolutely', 'abuse', 'academic', 'academic ability', 'academically']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Machine Learning Model Training and Testing**\n",
        "\n",
        "We will train and test three machine learning algorithms\n",
        "\n",
        "- SVM\n",
        "- Decision Trees\n",
        "- AdaBoostClassifier"
      ],
      "metadata": {
        "id": "5WLKuIcWyfPb"
      },
      "id": "5WLKuIcWyfPb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Model (Using GridSearchCV)"
      ],
      "metadata": {
        "id": "5NRtp7O0OPM-"
      },
      "id": "5NRtp7O0OPM-"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC(probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# The required parameter grid\n",
        "svm_param_grid = {\n",
        "    'vectorizer__max_features': [1000, 5000, 10000],\n",
        "    'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "    'classifier__C': [0.1, 1, 10, 100],\n",
        "    'classifier__kernel': ['linear', 'rbf'],\n",
        "    'classifier__gamma': ['scale', 'auto', 0.001, 0.01]  # Only for rbf kernel\n",
        "}\n",
        "\n",
        "# Setting up GridSearchCV with 5-fold cross-validation\n",
        "svm_grid = GridSearchCV(\n",
        "    svm_pipeline,\n",
        "    param_grid=svm_param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=3,\n",
        "    n_jobs=-1,\n",
        "    refit = True,\n",
        ")\n",
        "\n",
        "# Fitting grid search\n",
        "svm_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best SVM parameters: \", svm_grid.best_params_)\n",
        "\n",
        "# Best accuracy\n",
        "print(\"Best SVM accuracy: \", svm_grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FySrveKv_5d",
        "outputId": "c0182d26-de0c-4c27-9d52-173f0fedaceb"
      },
      "id": "8FySrveKv_5d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
            "Best SVM parameters:  {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear', 'vectorizer__max_features': 5000, 'vectorizer__ngram_range': (1, 3)}\n",
            "Best SVM accuracy:  0.9731684147808393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Trees Classifier"
      ],
      "metadata": {
        "id": "wgGscR_RX-0s"
      },
      "id": "wgGscR_RX-0s"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dt_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Parameter grid for Decision Tree\n",
        "dt_param_grid = {\n",
        "    'vectorizer__max_features': [1000, 5000, 10000],\n",
        "    'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "    'classifier__criterion': ['gini', 'entropy'],\n",
        "    'classifier__max_depth': [10, 20, 30, None],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Setting up GridSearchCV with 5-fold CV\n",
        "dt_grid = GridSearchCV(\n",
        "    estimator=dt_pipeline,\n",
        "    param_grid=dt_param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=3,\n",
        "    n_jobs=-1,\n",
        "    refit = True\n",
        ")\n",
        "\n",
        "# Training the GridSearchCV\n",
        "dt_grid.fit(X_train, y_train)\n",
        "\n",
        "# Output results\n",
        "print(\"Best Decision Tree Parameters:\", dt_grid.best_params_)\n",
        "print(\"Best Decision Tree Accuracy:\", dt_grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t89IFL6PwO9i",
        "outputId": "c1581505-b07c-48fb-9529-7446df93036b"
      },
      "id": "t89IFL6PwO9i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
            "Best Decision Tree Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'vectorizer__max_features': 5000, 'vectorizer__ngram_range': (1, 1)}\n",
            "Best Decision Tree Accuracy: 0.8708818139916585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoost Classifier"
      ],
      "metadata": {
        "id": "xGB6FGJHYJR-"
      },
      "id": "xGB6FGJHYJR-"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', AdaBoostClassifier(\n",
        "        estimator=DecisionTreeClassifier(max_depth=1),\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'clf__n_estimators':         [50, 100, 200],\n",
        "    'clf__learning_rate':        [0.01, 0.1, 1.0],\n",
        "    'clf__estimator__max_depth': [1, 2, 3]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)     # train\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"CV score:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlENAH662mwC",
        "outputId": "aab838bd-b6bd-46b1-a058-806daf85c08e"
      },
      "id": "mlENAH662mwC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "Best params: {'clf__estimator__max_depth': 3, 'clf__learning_rate': 1.0, 'clf__n_estimators': 200}\n",
            "CV score: 0.9664665609928837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Validation and Confusion Matrices for all the models"
      ],
      "metadata": {
        "id": "8mNHV7DoYNv4"
      },
      "id": "8mNHV7DoYNv4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM Model"
      ],
      "metadata": {
        "id": "aj4mitTsYUGd"
      },
      "id": "aj4mitTsYUGd"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Grab the refit pipeline\n",
        "svm_best_pipeline = svm_grid.best_estimator_\n",
        "\n",
        "# 2. Cross-validate accuracy\n",
        "svm_cv_scores = cross_val_score(\n",
        "    svm_best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(\"SVM CV Accuracy: %0.3f (+/- %0.3f)\" %\n",
        "      (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
        "\n",
        "# 3. Per-fold predictions to build a classification report & confusion matrix\n",
        "y_pred = cross_val_predict(\n",
        "    svm_best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh6lhQht_zB_",
        "outputId": "51d9ed55-1f20-4c82-b5ee-ceafee0f33b3"
      },
      "id": "sh6lhQht_zB_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM CV Accuracy: 0.973 (+/- 0.007)\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      1491\n",
            "           1       0.97      0.98      0.97      1491\n",
            "\n",
            "    accuracy                           0.97      2982\n",
            "   macro avg       0.97      0.97      0.97      2982\n",
            "weighted avg       0.97      0.97      0.97      2982\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1446   45]\n",
            " [  35 1456]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Trees Model"
      ],
      "metadata": {
        "id": "9IG0US_fYXWt"
      },
      "id": "9IG0US_fYXWt"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Grab the refit pipeline\n",
        "dt_best_pipeline = dt_grid.best_estimator_\n",
        "\n",
        "# 2. Cross-validate accuracy\n",
        "dt_cv_scores = cross_val_score(\n",
        "    dt_best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(\"DT CV Accuracy: %0.3f (+/- %0.3f)\" %\n",
        "      (dt_cv_scores.mean(), dt_cv_scores.std()))\n",
        "\n",
        "# 3. Per-fold predictions to build a classification report & confusion matrix\n",
        "y_pred = cross_val_predict(\n",
        "    dt_best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbcSaFRaYT1K",
        "outputId": "eb2bdf73-443f-4442-b334-3a7e14a43616"
      },
      "id": "BbcSaFRaYT1K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT CV Accuracy: 0.871 (+/- 0.017)\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87      1491\n",
            "           1       0.88      0.86      0.87      1491\n",
            "\n",
            "    accuracy                           0.87      2982\n",
            "   macro avg       0.87      0.87      0.87      2982\n",
            "weighted avg       0.87      0.87      0.87      2982\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1320  171]\n",
            " [ 214 1277]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AdaBoost Classifier Model"
      ],
      "metadata": {
        "id": "H4k0pBNeYaP3"
      },
      "id": "H4k0pBNeYaP3"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Grab the refit pipeline\n",
        "ada_best_pipeline = grid.best_estimator_\n",
        "\n",
        "# 2. Cross-validate accuracy\n",
        "ada_cv_scores = cross_val_score(\n",
        "    ada_best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(\"AdaBoost CV Accuracy: %0.3f (+/- %0.3f)\" %\n",
        "      (ada_cv_scores.mean(), ada_cv_scores.std()))\n",
        "\n",
        "# 3. Get per-fold predictions to build a classification report & confusion matrix\n",
        "y_pred = cross_val_predict(\n",
        "    ada_best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_lrOzUUm03M",
        "outputId": "866900d9-785c-445b-e590-d56201eee554"
      },
      "id": "N_lrOzUUm03M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost CV Accuracy: 0.966 (+/- 0.005)\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1491\n",
            "           1       0.97      0.97      0.97      1491\n",
            "\n",
            "    accuracy                           0.97      2982\n",
            "   macro avg       0.97      0.97      0.97      2982\n",
            "weighted avg       0.97      0.97      0.97      2982\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1443   48]\n",
            " [  52 1439]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deep Learning Models**"
      ],
      "metadata": {
        "id": "m5mfi25qkdp5"
      },
      "id": "m5mfi25qkdp5"
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset again due to some problems\n",
        "train_data = pd.read_excel('AI_vs_huam_train_dataset.xlsx')\n",
        "test_data = pd.read_csv('Final_test_data.csv')\n",
        "\n",
        "# --------------------\n",
        "# Tokenizer + Vocab\n",
        "# --------------------\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "counter = Counter()\n",
        "for essay in train_data['essay']:\n",
        "    counter.update(tokenize(essay))\n",
        "\n",
        "vocab = {word: idx+2 for idx, (word, _) in enumerate(counter.items())}\n",
        "vocab['<PAD>'] = 0\n",
        "vocab['<UNK>'] = 1\n",
        "\n",
        "with open(\"vocab.pkl\", \"wb\") as f:\n",
        "    import pickle\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "# --------------------\n",
        "# Encode function\n",
        "# --------------------\n",
        "def encode(text):\n",
        "    return [vocab.get(token, 1) for token in tokenize(text)]\n",
        " # --------------------\n",
        "# Dataset + Collate\n",
        "# --------------------\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, essays, labels=None):\n",
        "        self.essays = [torch.tensor(encode(e)) for e in essays]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.essays)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return self.essays[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.essays[idx]\n",
        "\n",
        "def collate_batch(batch):\n",
        "    if isinstance(batch[0], tuple):\n",
        "        essays, labels = zip(*batch)\n",
        "        essays_padded = pad_sequence(essays, batch_first=True, padding_value=0)\n",
        "        return essays_padded, torch.tensor(labels)\n",
        "    else:\n",
        "        essays_padded = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "        return essays_padded\n",
        "\n",
        "# --------------------\n",
        "# DataLoaders\n",
        "# --------------------\n",
        "y_train = train_data['label'].tolist()\n",
        "dataset = EssayDataset(train_data['essay'], y_train)\n",
        "train_len = int(0.8 * len(dataset))\n",
        "val_len = len(dataset) - train_len\n",
        "train_dataset, val_dataset = random_split(dataset, [train_len, val_len])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "PQHwDpohmPGg"
      },
      "id": "PQHwDpohmPGg",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Model"
      ],
      "metadata": {
        "id": "_DUGqYSrnWo-"
      },
      "id": "_DUGqYSrnWo-"
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=256, output_dim=2, dropout=0.5):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(embedded)\n",
        "        out = self.dropout(hidden[-1])\n",
        "        return self.fc(out)"
      ],
      "metadata": {
        "id": "HiiixS4zpDGj"
      },
      "id": "HiiixS4zpDGj",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model"
      ],
      "metadata": {
        "id": "K-15BKgZnbbt"
      },
      "id": "K-15BKgZnbbt"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=100, num_filters=128, filter_sizes=[3,4,5], output_dim=2, dropout=0.5):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (fs, embed_dim)) for fs in filter_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x).unsqueeze(1)\n",
        "        conved = [torch.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [torch.max(c, dim=2)[0] for c in conved]\n",
        "        cat = torch.cat(pooled, dim=1)\n",
        "        out = self.dropout(cat)\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "uHbbE1lFpNGo"
      },
      "id": "uHbbE1lFpNGo",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Model"
      ],
      "metadata": {
        "id": "jLBEwtgznp_2"
      },
      "id": "jLBEwtgznp_2"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=512, output_dim=2, dropout=0.5, bidirectional=True):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True, bidirectional=bidirectional)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, hidden = self.rnn(embedded)\n",
        "        if isinstance(hidden, tuple):  # just safety if ever swapped\n",
        "            hidden = hidden[0]\n",
        "        if self.rnn.bidirectional:\n",
        "            out = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        else:\n",
        "            out = hidden[-1]\n",
        "        out = self.dropout(out)\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "ptIZn_8BpQ6t"
      },
      "id": "ptIZn_8BpQ6t",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the models"
      ],
      "metadata": {
        "id": "uSmHqS2qpYfw"
      },
      "id": "uSmHqS2qpYfw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Training the models"
      ],
      "metadata": {
        "id": "ue-V5mIdpT0_"
      },
      "id": "ue-V5mIdpT0_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted loss\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# --------------------\n",
        "# Train function (generic)\n",
        "# --------------------\n",
        "def train_model(model, name, optimizer, num_epochs=20, patience=3):\n",
        "    best_val_acc = 0\n",
        "    trigger_times = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in val_loader:\n",
        "                outputs = model(x_batch)\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                correct += (preds == y_batch).sum().item()\n",
        "                total += y_batch.size(0)\n",
        "        val_acc = correct / total\n",
        "        print(f\"{name} - Epoch {epoch+1}, Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            trigger_times = 0\n",
        "            torch.save(model.state_dict(), f\"best_{name}_model.pt\")\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "    print(f\"Best Validation Accuracy for {name}: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "qZeYp6wdpcRr"
      },
      "id": "qZeYp6wdpcRr",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training LSTM"
      ],
      "metadata": {
        "id": "q8LZVccQqFK0"
      },
      "id": "q8LZVccQqFK0"
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = LSTMClassifier(len(vocab))\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.0005)\n",
        "train_model(lstm_model, \"lstm\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EfpnWZ7p9Q3",
        "outputId": "87396480-7990-43bd-b4a3-4ee390a515d5"
      },
      "id": "7EfpnWZ7p9Q3",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm - Epoch 1, Val Accuracy: 0.5255\n",
            "lstm - Epoch 2, Val Accuracy: 0.5228\n",
            "lstm - Epoch 3, Val Accuracy: 0.5295\n",
            "lstm - Epoch 4, Val Accuracy: 0.5282\n",
            "lstm - Epoch 5, Val Accuracy: 0.5241\n",
            "lstm - Epoch 6, Val Accuracy: 0.5308\n",
            "lstm - Epoch 7, Val Accuracy: 0.6206\n",
            "lstm - Epoch 8, Val Accuracy: 0.5912\n",
            "lstm - Epoch 9, Val Accuracy: 0.5670\n",
            "lstm - Epoch 10, Val Accuracy: 0.7534\n",
            "lstm - Epoch 11, Val Accuracy: 0.8298\n",
            "lstm - Epoch 12, Val Accuracy: 0.9115\n",
            "lstm - Epoch 13, Val Accuracy: 0.9491\n",
            "lstm - Epoch 14, Val Accuracy: 0.9477\n",
            "lstm - Epoch 15, Val Accuracy: 0.9665\n",
            "lstm - Epoch 16, Val Accuracy: 0.9611\n",
            "lstm - Epoch 17, Val Accuracy: 0.9571\n",
            "lstm - Epoch 18, Val Accuracy: 0.9625\n",
            "Early stopping triggered.\n",
            "Best Validation Accuracy for lstm: 0.9665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training CNN"
      ],
      "metadata": {
        "id": "B9UUtQ-BqKGN"
      },
      "id": "B9UUtQ-BqKGN"
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = CNNClassifier(len(vocab))\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.0005)\n",
        "train_model(cnn_model, \"cnn\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0yk59SwqLHK",
        "outputId": "8e67da51-b0bc-49e5-fa54-a3c65359413e"
      },
      "id": "K0yk59SwqLHK",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn - Epoch 1, Val Accuracy: 0.9223\n",
            "cnn - Epoch 2, Val Accuracy: 0.9290\n",
            "cnn - Epoch 3, Val Accuracy: 0.9517\n",
            "cnn - Epoch 4, Val Accuracy: 0.9531\n",
            "cnn - Epoch 5, Val Accuracy: 0.9611\n",
            "cnn - Epoch 6, Val Accuracy: 0.9611\n",
            "cnn - Epoch 7, Val Accuracy: 0.9665\n",
            "cnn - Epoch 8, Val Accuracy: 0.9692\n",
            "cnn - Epoch 9, Val Accuracy: 0.9705\n",
            "cnn - Epoch 10, Val Accuracy: 0.9732\n",
            "cnn - Epoch 11, Val Accuracy: 0.9705\n",
            "cnn - Epoch 12, Val Accuracy: 0.9745\n",
            "cnn - Epoch 13, Val Accuracy: 0.9692\n",
            "cnn - Epoch 14, Val Accuracy: 0.9705\n",
            "cnn - Epoch 15, Val Accuracy: 0.9705\n",
            "Early stopping triggered.\n",
            "Best Validation Accuracy for cnn: 0.9745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning RNN"
      ],
      "metadata": {
        "id": "8Z60wU_FqP7Q"
      },
      "id": "8Z60wU_FqP7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = RNNClassifier(len(vocab), embed_dim=100, hidden_dim=512, output_dim=2, dropout=0.5, bidirectional=True)\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.0005)\n",
        "train_model(rnn_model, \"rnn\", optimizer, num_epochs=40, patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFXK5clcqTBZ",
        "outputId": "81dbe05e-38d2-4748-92c5-793022488172"
      },
      "id": "yFXK5clcqTBZ",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rnn - Epoch 1, Val Accuracy: 0.6676\n",
            "rnn - Epoch 2, Val Accuracy: 0.7426\n",
            "rnn - Epoch 3, Val Accuracy: 0.7828\n",
            "rnn - Epoch 4, Val Accuracy: 0.5228\n",
            "rnn - Epoch 5, Val Accuracy: 0.5080\n",
            "rnn - Epoch 6, Val Accuracy: 0.5416\n",
            "rnn - Epoch 7, Val Accuracy: 0.5322\n",
            "rnn - Epoch 8, Val Accuracy: 0.5308\n",
            "Early stopping triggered.\n",
            "Best Validation Accuracy for rnn: 0.7828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the models"
      ],
      "metadata": {
        "id": "WCeBiqiZqXOC"
      },
      "id": "WCeBiqiZqXOC"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(rnn_model.state_dict(), \"rnn_model.pkl\")\n",
        "torch.save(lstm_model.state_dict(), \"lstm_model.pkl\")\n",
        "torch.save(cnn_model.state_dict(), \"cnn_model.pkl\")"
      ],
      "metadata": {
        "id": "T2cOd-5dqZ_L"
      },
      "id": "T2cOd-5dqZ_L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Model saving for Streamlit deployment**"
      ],
      "metadata": {
        "id": "m7yI4WV5wrt8"
      },
      "id": "m7yI4WV5wrt8"
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_predictions = svm_pipeline.predict(X_val)\n",
        "pipeline_accuracy = metrics.accuracy_score(y_val, pipeline_predictions)\n",
        "\n",
        "print(\"Final Pipeline Results:\")\n",
        "print(f\"Validation accuracy: {pipeline_accuracy:.4f}\")\n",
        "\n",
        "# Show detailed classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "target_names = ['Human', 'AI']\n",
        "classification_report = metrics.classification_report(y_val, pipeline_predictions, target_names=target_names)\n",
        "print(classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD_uJQvrw7UF",
        "outputId": "bddcb7a2-5709-400b-fc51-255ecdc81b09"
      },
      "id": "DD_uJQvrw7UF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pipeline Results:\n",
            "Validation accuracy: 0.9692\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.97      0.97      0.97       373\n",
            "          AI       0.97      0.97      0.97       373\n",
            "\n",
            "    accuracy                           0.97       746\n",
            "   macro avg       0.97      0.97      0.97       746\n",
            "weighted avg       0.97      0.97      0.97       746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Models for Streamlit Deployment\n",
        "\n",
        "print(\"Saving models for Streamlit deployment...\")\n",
        "\n",
        "# Save the complete pipeline (includes TF-IDF + classifier)\n",
        "pipeline_filename = 'human_ai_pipeline.pkl'\n",
        "joblib.dump(svm_best_pipeline, pipeline_filename)\n",
        "\n",
        "# Also save individual components for flexibility\n",
        "tfidf_filename = 'tfidf_vectorizer.pkl'\n",
        "\n",
        "joblib.dump(tfidf_vectorizer, tfidf_filename)\n",
        "\n",
        "print(\"Models saved successfully!\")\n",
        "print(f\"Complete pipeline: {pipeline_filename}\")\n",
        "print(f\"TF-IDF vectorizer: {tfidf_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMnNQ9M3xG4G",
        "outputId": "98cae212-73ab-4890-b82a-e6fdac8c6dbe"
      },
      "id": "vMnNQ9M3xG4G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models for Streamlit deployment...\n",
            "Models saved successfully!\n",
            "Complete pipeline: human_ai_pipeline.pkl\n",
            "TF-IDF vectorizer: tfidf_vectorizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.  For Decision Tree classifier"
      ],
      "metadata": {
        "id": "jcz3mafTQ4tt"
      },
      "id": "jcz3mafTQ4tt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test classifier performance\n",
        "dt_predictions = dt_best_pipeline.predict(X_val)\n",
        "dt_accuracy = metrics.accuracy_score(y_val, dt_predictions)\n",
        "\n",
        "print(f\"\\Decision Tree Results:\")\n",
        "print(f\"Validation accuracy: {dt_accuracy:.4f}\")\n",
        "\n",
        "# Show detailed classification report\n",
        "print(\"\\nDetailed Classification Report - Decision Trees:\")\n",
        "target_names = ['Human', 'AI']\n",
        "dt_classification_report = metrics.classification_report(y_val, dt_predictions, target_names=target_names)\n",
        "print(dt_classification_report)\n",
        "\n",
        "# Save DT Classifier\n",
        "print(\"Saving Decision Trees Classifier\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save the DT classifier\n",
        "dt_model_filename = 'decision_tree_model.pkl'\n",
        "print(\"Saving Decision Tree classifier...\")\n",
        "joblib.dump(dt_best_pipeline, dt_model_filename)\n",
        "\n",
        "print(f\"\\n Decision Trees classifier saved as: {dt_model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAFe5rRJTF3V",
        "outputId": "15431046-072c-4f33-9daf-2da2622550be"
      },
      "id": "OAFe5rRJTF3V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\Decision Tree Results:\n",
            "Validation accuracy: 0.8606\n",
            "\n",
            "Detailed Classification Report - Decision Trees:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.83      0.90      0.87       373\n",
            "          AI       0.89      0.82      0.85       373\n",
            "\n",
            "    accuracy                           0.86       746\n",
            "   macro avg       0.86      0.86      0.86       746\n",
            "weighted avg       0.86      0.86      0.86       746\n",
            "\n",
            "Saving Decision Trees Classifier\n",
            "============================================================\n",
            "Saving Decision Tree classifier...\n",
            "\n",
            " Decision Trees classifier saved as: decision_tree_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. For AdaBoost Classifier\n"
      ],
      "metadata": {
        "id": "Z5tqgdgymuBH"
      },
      "id": "Z5tqgdgymuBH"
    },
    {
      "cell_type": "code",
      "source": [
        "ada_predictions = ada_best_pipeline.predict(X_val)\n",
        "ada_accuracy = metrics.accuracy_score(y_val, ada_predictions)\n",
        "\n",
        "print(f\"\\AdaBoost Results:\")\n",
        "print(f\"Validation accuracy: {ada_accuracy:.4f}\")\n",
        "\n",
        "# Showing detailed classification report\n",
        "print(\"\\nDetailed Classification Report - AdaBoost Classifier:\")\n",
        "target_names = ['Human', 'AI']\n",
        "ada_classification_report = metrics.classification_report(y_val, ada_predictions, target_names=target_names)\n",
        "print(ada_classification_report)\n",
        "\n",
        "# Saving The AdaBoost Classifier\n",
        "print(\"Saving AdaBoost Classifier\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Saving the AdaBoost classifier\n",
        "ada_model_filename = 'adaBoost_model.pkl'\n",
        "print(\"Saving Decision Tree classifier...\")\n",
        "joblib.dump(ada_best_pipeline, ada_model_filename)\n",
        "\n",
        "print(f\"\\n AdaBoost Classifier saved as: {ada_model_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a42ew2M3mwlI",
        "outputId": "12c3d1cb-8a23-4fb9-d02c-3bce4804a6bc"
      },
      "id": "a42ew2M3mwlI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\AdaBoost Results:\n",
            "Validation accuracy: 0.9705\n",
            "\n",
            "Detailed Classification Report - AdaBoost Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.97      0.97      0.97       373\n",
            "          AI       0.97      0.97      0.97       373\n",
            "\n",
            "    accuracy                           0.97       746\n",
            "   macro avg       0.97      0.97      0.97       746\n",
            "weighted avg       0.97      0.97      0.97       746\n",
            "\n",
            "Saving AdaBoost Classifier\n",
            "============================================================\n",
            "Saving Decision Tree classifier...\n",
            "\n",
            " AdaBoost Classifier saved as: adaBoost_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test the Test Data on the Saved Models**"
      ],
      "metadata": {
        "id": "G_61h1F0V3-B"
      },
      "id": "G_61h1F0V3-B"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df_test['essay']\n",
        "Y_test = df_test['label']\n",
        "test_essay = X_test.head()\n",
        "print(test_essay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-Kc0jcxW0qc",
        "outputId": "b6e94e89-356e-4731-b3f6-198739368d4f"
      },
      "id": "4-Kc0jcxW0qc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Enjoyment means entertainment, satisfaction of...\n",
            "1    Before to start with my opinion of the topic i...\n",
            "2    Thats a really really good subject, but acctul...\n",
            "3    I disagree with the statement saying that it i...\n",
            "4    It is undeniable that advertisements play a si...\n",
            "Name: essay, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading TF-IDF Vectorizer and Saved ML models**"
      ],
      "metadata": {
        "id": "Z0U-YB5LXIxJ"
      },
      "id": "Z0U-YB5LXIxJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load existing TF-IDF vectorizer\n",
        "print(\"Loading existing TF-IDF vectorizer...\")\n",
        "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "print(\"TF-IDF vectorizer loaded successfully!\")\n",
        "\n",
        "# Load the saved DT classifier\n",
        "print(\"Loading saved DT classifier pipeline...\")\n",
        "loaded_dt_classifier = joblib.load('decision_tree_model.pkl')\n",
        "print(\"‚úÖ Decision Tree loaded successfully!\")\n",
        "dt_available = True\n",
        "\n",
        "# Load the saved SVM Classifier for comparison\n",
        "print(\"Loading saved SVM pipeline...\")\n",
        "loaded_pipeline_svm = joblib.load('human_ai_pipeline.pkl')\n",
        "svm_available = True\n",
        "print(\"‚úÖ SVM pipeline loaded successfully!\")\n",
        "\n",
        "# Load the saved AdaBoost Classifier\n",
        "print(\"Loading saved AdaBoost classifier pipeline...\")\n",
        "loaded_ada_classifier = joblib.load('adaBoost_model.pkl')\n",
        "print(\"‚úÖ AdaBoost Classifier loaded successfully!\")\n",
        "ada_available = True\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbXu-jBOXq3t",
        "outputId": "ac389f8d-3b70-4d04-f098-a100766268c5"
      },
      "id": "EbXu-jBOXq3t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing TF-IDF vectorizer...\n",
            "TF-IDF vectorizer loaded successfully!\n",
            "Loading saved DT classifier pipeline...\n",
            "‚úÖ Decision Tree loaded successfully!\n",
            "Loading saved SVM pipeline...\n",
            "‚úÖ SVM pipeline loaded successfully!\n",
            "Loading saved AdaBoost classifier pipeline...\n",
            "‚úÖ AdaBoost Classifier loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "jHFFHUBnRsGM"
      },
      "id": "jHFFHUBnRsGM"
    },
    {
      "cell_type": "code",
      "source": [
        "if dt_available:\n",
        "  print(\"Testing Decision Trees predictions...\")\n",
        "\n",
        "  for i, essay in enumerate(test_essay, 1):\n",
        "    print(f\"{i}. Test: {essay}\")\n",
        "    dt_prediction = loaded_dt_classifier.predict(X_test)\n",
        "\n",
        "    print()\n",
        "else:\n",
        "  print(\"Cannot test DT - model not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ihcs4An0LJS",
        "outputId": "ba39419c-2a5e-4fbe-cb5a-47053eab4b8d"
      },
      "id": "1Ihcs4An0LJS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Decision Trees predictions...\n",
            "1. Test: Enjoyment means entertainment, satisfaction of one's soul and containment with the happenings in life. I would like to disagree with this statement. This is because entertainment would mean differently to different people. Entertainment depends on various factors like the person's attitude and his notion or perspective on entertainment.\n",
            "   The younger generation tends to enjoy themselves by going to parties, meeting new people, making new friends and going for long drives. The way a youngster enjoys himself or herself depends on the attitude and nature of the individual. Some people might like to go to parties for entertainment while others might like to watch a movie.\n",
            "   On the other hand the older people might also do the same things that youngsters do or they may engage in activities considered as dull and boring by the youngsters. I would like to take examples of two famous personalities here who despite their age never complained of boredom. Firstly, I would like to take the example of Mother Teresa who despite her old age found enjoyment in playing with children and serving the needy. Secondly, I would like to take the example of the famous painter, M.F. Hussain. M.F. Hussain is more than eighty years old but finds enjoyment in his paintings. He likes to draw and finds his entertainment in his drawings. \n",
            "   We can find people both among younsters and aged who remain depressed and do not tend to enjoy themselves. They lead the life of a loner and stay in recluse. The youngsters have a pressure to make their life which may in turn have an effect on the way they tend to enjoy themselves. But this might not be the case with the older people. They have a life, they have attained their goals and can live a peaceful life which in itself is an enjoyment.The old people also tend to enjoy themselves by talking to others of their age and about their life's experiences.\n",
            "    Thus we see that the entire concept of enjoyment differs from one person to other. We can never say with surity that youngsters tend to enjoy more than the old people. Everything depends on the nature and the attitude of people. If somebody wants to enjoy age is never a deciding factor. It's the perspective and the likes and dislikes of a person which tends to decide how well the person is enjoying his life.\n",
            "\n",
            "2. Test: Before to start with my opinion of the topic i must to say that in this life what is the much important thing of a product? So if we want to responde about this question we can tell that the image of a product it's very important but it's only a vision fact. So I agree with the topic.\n",
            "\n",
            "The advertisements make products seem a good image, so the people are involved to buy these. They show us the best quality of products and not the reality. An example is if you want buy a car you see that this car is the best for speed, or elegance, or horse power, or other characterists but you don't see what is the consume, if the power of this car is economicaly good. \n",
            "\n",
            "But the advertisments are in all our life, becouse if you watch TV shows or programs there are many break of advertisements, if you read a newspaper there are pages and pages of advertisements, when you go to work or only you go out in the streets you can see more and more advertisements. So they are a subliminar message. And the power of its is that can seem products better than really are.\n",
            "     \n",
            "However, the advertisements are most important for the economy because a good advertisements can make some profit for the industries. But the buyers have one thing from their side, that the product is much far from reality they can't buy it. \n",
            "\n",
            "In conclusion I'm in accord at the topic but i tell to all the people of the world that not are impressionate for the apperance of an advertisement but see the really quality of products, that we can change something in the world.\n",
            "\n",
            "3. Test: Thats a really really good subject, but acctully i have to say that i agree with specializing in one thing, Beacuse if some one did then when he well give 100% to making his catagory the best and making his job the best. Like if we had a cardiac doctor if you asked him he well tell you that he is trying to be the best and to invent a new methods to fix the heart. so, At the end of the road if he was ambesiuos he can do it . all am saying that its better to specialize in on subject.one, its better to improve that subject.two, it well be better for him not to be puzzled.and three,it well make him the best in that subject. however, i think the its good to have a broad knowledge but while foucsing on one major. like some one is an engeneering but at the same time he can creat other bussnis away from his major,like he could work at the stocks or open a store to sell any thing.but, there is some thing verey importanat. that this other work well not effect his major work beacuse in this way he will be a loser in both subjects. anyway my point is that both of them is good.but, for some people that is good for others the other one is better. and as the old sayin\"defers in opinun will not destroy the case\".but i said mine and thank you for this verey good subject and thatsall i have to say.\n",
            "\n",
            "4. Test: I disagree with the statement saying that it is better to have broad knowledge of many subjects rather than specializing in one specific subject. I will illustrate my views below.\n",
            "\n",
            "There is an English proverb which beautifully fits in the above case: \"A Jack of all is a master of none.\"\n",
            "In the past scientific knowledge was relatively limited as compared to now. Now many new fields have been developed and even in a single field there are many sub divisions. For e.g. Computers. Before there no sub-divisions in the field of computers but now we can broadly classify them as Hardware, software, Middle-ware, Internet & Networking, etc.\n",
            "Even in these sub-divisions we can have several more options.\n",
            "The point I am trying to make here is that fields are more diverse and varied then they were before. Hence it is simply not possible to excel in all of them and having only a general idea about them will not suffice.\n",
            "\n",
            "Additionally knowledge has become more and more complex than before. Having a general idea about things is not enough to perform the tasks adequately. For e.g. A CFO (Chief Financial Officer) of a company has reasonable knowledge about Law. So does it mean that he will be as competent as a Lawyer specialising in these tasks? Alternatively a lawyer cannot do adequate justice to the job of a CFO.\n",
            "\n",
            "Let me illustrate my point further. Would you like to live in a building which has been made by person having a \"general\" idea of construction, architecture and engineering or would prefer living in a building made by a team of experts in their respective fields. Focus on one topic inspires confidence not only in others but also in the person doing the job. \n",
            "\n",
            "Hence with the points above I have best tried to justify my conclusion.\n",
            "\n",
            "5. Test: It is undeniable that advertisements play a significant role in shaping consumer perceptions and influencing purchasing decisions. While some advertisements may accurately portray products, I strongly agree that most advertisements tend to exaggerate the benefits and qualities of products, making them seem far better than they truly are. This tendency is driven by the inherent goal of advertising: to persuade consumers to buy. \n",
            "\n",
            "One common tactic employed by advertisers is the use of selective information and misleading claims. For instance, a commercial for a weight-loss product might showcase individuals who have achieved dramatic results, while conveniently omitting the fact that these individuals may have also undergone rigorous exercise regimes and dietary changes. This selective presentation creates a false impression of the product's effectiveness. \n",
            "\n",
            "Furthermore, advertisements often rely heavily on emotional appeals and visual imagery to evoke positive associations with the product. A car commercial might feature a sleek, luxurious car driving through scenic landscapes, implying that owning the car will bring happiness and freedom. However, the reality is that the car itself does not guarantee these feelings. \n",
            "\n",
            "In conclusion, while some advertisements may be informative and truthful, the majority tend to embellish the qualities of products to create a more appealing image. By selectively presenting information, using emotional appeals, and employing visual trickery, advertisers aim to persuade consumers to buy products that may not live up to their exaggerated promises. It is crucial for consumers to be aware of these tactics and to critically evaluate advertising messages before making purchasing decisions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ada_available:\n",
        "  print(\"Testing AdaBoost predictions...\")\n",
        "\n",
        "  for i, essay in enumerate(test_essay, 1):\n",
        "    print(f\"{i}. Test: {essay}\")\n",
        "    ada_prediction = loaded_ada_classifier.predict(X_test)\n",
        "\n",
        "    print()\n",
        "else:\n",
        "  print(\"Cannot test AdaBoost - model not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IHB1wkcRyuF",
        "outputId": "7af90a07-e987-4c09-e7a4-13eb9a82e2a1"
      },
      "id": "3IHB1wkcRyuF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing AdaBoost predictions...\n",
            "1. Test: Enjoyment means entertainment, satisfaction of one's soul and containment with the happenings in life. I would like to disagree with this statement. This is because entertainment would mean differently to different people. Entertainment depends on various factors like the person's attitude and his notion or perspective on entertainment.\n",
            "   The younger generation tends to enjoy themselves by going to parties, meeting new people, making new friends and going for long drives. The way a youngster enjoys himself or herself depends on the attitude and nature of the individual. Some people might like to go to parties for entertainment while others might like to watch a movie.\n",
            "   On the other hand the older people might also do the same things that youngsters do or they may engage in activities considered as dull and boring by the youngsters. I would like to take examples of two famous personalities here who despite their age never complained of boredom. Firstly, I would like to take the example of Mother Teresa who despite her old age found enjoyment in playing with children and serving the needy. Secondly, I would like to take the example of the famous painter, M.F. Hussain. M.F. Hussain is more than eighty years old but finds enjoyment in his paintings. He likes to draw and finds his entertainment in his drawings. \n",
            "   We can find people both among younsters and aged who remain depressed and do not tend to enjoy themselves. They lead the life of a loner and stay in recluse. The youngsters have a pressure to make their life which may in turn have an effect on the way they tend to enjoy themselves. But this might not be the case with the older people. They have a life, they have attained their goals and can live a peaceful life which in itself is an enjoyment.The old people also tend to enjoy themselves by talking to others of their age and about their life's experiences.\n",
            "    Thus we see that the entire concept of enjoyment differs from one person to other. We can never say with surity that youngsters tend to enjoy more than the old people. Everything depends on the nature and the attitude of people. If somebody wants to enjoy age is never a deciding factor. It's the perspective and the likes and dislikes of a person which tends to decide how well the person is enjoying his life.\n",
            "\n",
            "2. Test: Before to start with my opinion of the topic i must to say that in this life what is the much important thing of a product? So if we want to responde about this question we can tell that the image of a product it's very important but it's only a vision fact. So I agree with the topic.\n",
            "\n",
            "The advertisements make products seem a good image, so the people are involved to buy these. They show us the best quality of products and not the reality. An example is if you want buy a car you see that this car is the best for speed, or elegance, or horse power, or other characterists but you don't see what is the consume, if the power of this car is economicaly good. \n",
            "\n",
            "But the advertisments are in all our life, becouse if you watch TV shows or programs there are many break of advertisements, if you read a newspaper there are pages and pages of advertisements, when you go to work or only you go out in the streets you can see more and more advertisements. So they are a subliminar message. And the power of its is that can seem products better than really are.\n",
            "     \n",
            "However, the advertisements are most important for the economy because a good advertisements can make some profit for the industries. But the buyers have one thing from their side, that the product is much far from reality they can't buy it. \n",
            "\n",
            "In conclusion I'm in accord at the topic but i tell to all the people of the world that not are impressionate for the apperance of an advertisement but see the really quality of products, that we can change something in the world.\n",
            "\n",
            "3. Test: Thats a really really good subject, but acctully i have to say that i agree with specializing in one thing, Beacuse if some one did then when he well give 100% to making his catagory the best and making his job the best. Like if we had a cardiac doctor if you asked him he well tell you that he is trying to be the best and to invent a new methods to fix the heart. so, At the end of the road if he was ambesiuos he can do it . all am saying that its better to specialize in on subject.one, its better to improve that subject.two, it well be better for him not to be puzzled.and three,it well make him the best in that subject. however, i think the its good to have a broad knowledge but while foucsing on one major. like some one is an engeneering but at the same time he can creat other bussnis away from his major,like he could work at the stocks or open a store to sell any thing.but, there is some thing verey importanat. that this other work well not effect his major work beacuse in this way he will be a loser in both subjects. anyway my point is that both of them is good.but, for some people that is good for others the other one is better. and as the old sayin\"defers in opinun will not destroy the case\".but i said mine and thank you for this verey good subject and thatsall i have to say.\n",
            "\n",
            "4. Test: I disagree with the statement saying that it is better to have broad knowledge of many subjects rather than specializing in one specific subject. I will illustrate my views below.\n",
            "\n",
            "There is an English proverb which beautifully fits in the above case: \"A Jack of all is a master of none.\"\n",
            "In the past scientific knowledge was relatively limited as compared to now. Now many new fields have been developed and even in a single field there are many sub divisions. For e.g. Computers. Before there no sub-divisions in the field of computers but now we can broadly classify them as Hardware, software, Middle-ware, Internet & Networking, etc.\n",
            "Even in these sub-divisions we can have several more options.\n",
            "The point I am trying to make here is that fields are more diverse and varied then they were before. Hence it is simply not possible to excel in all of them and having only a general idea about them will not suffice.\n",
            "\n",
            "Additionally knowledge has become more and more complex than before. Having a general idea about things is not enough to perform the tasks adequately. For e.g. A CFO (Chief Financial Officer) of a company has reasonable knowledge about Law. So does it mean that he will be as competent as a Lawyer specialising in these tasks? Alternatively a lawyer cannot do adequate justice to the job of a CFO.\n",
            "\n",
            "Let me illustrate my point further. Would you like to live in a building which has been made by person having a \"general\" idea of construction, architecture and engineering or would prefer living in a building made by a team of experts in their respective fields. Focus on one topic inspires confidence not only in others but also in the person doing the job. \n",
            "\n",
            "Hence with the points above I have best tried to justify my conclusion.\n",
            "\n",
            "5. Test: It is undeniable that advertisements play a significant role in shaping consumer perceptions and influencing purchasing decisions. While some advertisements may accurately portray products, I strongly agree that most advertisements tend to exaggerate the benefits and qualities of products, making them seem far better than they truly are. This tendency is driven by the inherent goal of advertising: to persuade consumers to buy. \n",
            "\n",
            "One common tactic employed by advertisers is the use of selective information and misleading claims. For instance, a commercial for a weight-loss product might showcase individuals who have achieved dramatic results, while conveniently omitting the fact that these individuals may have also undergone rigorous exercise regimes and dietary changes. This selective presentation creates a false impression of the product's effectiveness. \n",
            "\n",
            "Furthermore, advertisements often rely heavily on emotional appeals and visual imagery to evoke positive associations with the product. A car commercial might feature a sleek, luxurious car driving through scenic landscapes, implying that owning the car will bring happiness and freedom. However, the reality is that the car itself does not guarantee these feelings. \n",
            "\n",
            "In conclusion, while some advertisements may be informative and truthful, the majority tend to embellish the qualities of products to create a more appealing image. By selectively presenting information, using emotional appeals, and employing visual trickery, advertisers aim to persuade consumers to buy products that may not live up to their exaggerated promises. It is crucial for consumers to be aware of these tactics and to critically evaluate advertising messages before making purchasing decisions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test SVM Model\n",
        "# Option 1: Use Pipeline\n",
        "\n",
        "print(\"OPTION 1: Testing SVM Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load the saved pipeline\n",
        "loaded_pipeline_svm = joblib.load(pipeline_filename)\n",
        "\n",
        "for i, text in enumerate(test_essay, 1):\n",
        "    # Use raw text - let pipeline handle all preprocessing\n",
        "    prediction = loaded_pipeline_svm.predict([text])[0]\n",
        "    probability = loaded_pipeline_svm.predict_proba([text])[0]\n",
        "\n",
        "    classification = \"Human\" if prediction == 0 else \"AI\"\n",
        "    confidence = max(probability)\n",
        "\n",
        "    print(f\"{i}. Text: {text}\")\n",
        "    print(f\"\\n   Prediction: {classification} (Confidence: {confidence:.3f})\")\n",
        "    print(f\"\\n  Probabilities: Human: {probability[0]:.3f}, AI: {probability[1]:.3f}\")\n",
        "    print()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfdb71CbaWD0",
        "outputId": "dea1dd46-647e-49e6-b6d2-f1e2fd8059b4"
      },
      "id": "zfdb71CbaWD0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPTION 1: Testing SVM Pipeline\n",
            "============================================================\n",
            "1. Text: Enjoyment means entertainment, satisfaction of one's soul and containment with the happenings in life. I would like to disagree with this statement. This is because entertainment would mean differently to different people. Entertainment depends on various factors like the person's attitude and his notion or perspective on entertainment.\n",
            "   The younger generation tends to enjoy themselves by going to parties, meeting new people, making new friends and going for long drives. The way a youngster enjoys himself or herself depends on the attitude and nature of the individual. Some people might like to go to parties for entertainment while others might like to watch a movie.\n",
            "   On the other hand the older people might also do the same things that youngsters do or they may engage in activities considered as dull and boring by the youngsters. I would like to take examples of two famous personalities here who despite their age never complained of boredom. Firstly, I would like to take the example of Mother Teresa who despite her old age found enjoyment in playing with children and serving the needy. Secondly, I would like to take the example of the famous painter, M.F. Hussain. M.F. Hussain is more than eighty years old but finds enjoyment in his paintings. He likes to draw and finds his entertainment in his drawings. \n",
            "   We can find people both among younsters and aged who remain depressed and do not tend to enjoy themselves. They lead the life of a loner and stay in recluse. The youngsters have a pressure to make their life which may in turn have an effect on the way they tend to enjoy themselves. But this might not be the case with the older people. They have a life, they have attained their goals and can live a peaceful life which in itself is an enjoyment.The old people also tend to enjoy themselves by talking to others of their age and about their life's experiences.\n",
            "    Thus we see that the entire concept of enjoyment differs from one person to other. We can never say with surity that youngsters tend to enjoy more than the old people. Everything depends on the nature and the attitude of people. If somebody wants to enjoy age is never a deciding factor. It's the perspective and the likes and dislikes of a person which tends to decide how well the person is enjoying his life.\n",
            "\n",
            "   Prediction: Human (Confidence: 0.971)\n",
            "\n",
            "  Probabilities: Human: 0.971, AI: 0.029\n",
            "\n",
            "2. Text: Before to start with my opinion of the topic i must to say that in this life what is the much important thing of a product? So if we want to responde about this question we can tell that the image of a product it's very important but it's only a vision fact. So I agree with the topic.\n",
            "\n",
            "The advertisements make products seem a good image, so the people are involved to buy these. They show us the best quality of products and not the reality. An example is if you want buy a car you see that this car is the best for speed, or elegance, or horse power, or other characterists but you don't see what is the consume, if the power of this car is economicaly good. \n",
            "\n",
            "But the advertisments are in all our life, becouse if you watch TV shows or programs there are many break of advertisements, if you read a newspaper there are pages and pages of advertisements, when you go to work or only you go out in the streets you can see more and more advertisements. So they are a subliminar message. And the power of its is that can seem products better than really are.\n",
            "     \n",
            "However, the advertisements are most important for the economy because a good advertisements can make some profit for the industries. But the buyers have one thing from their side, that the product is much far from reality they can't buy it. \n",
            "\n",
            "In conclusion I'm in accord at the topic but i tell to all the people of the world that not are impressionate for the apperance of an advertisement but see the really quality of products, that we can change something in the world.\n",
            "\n",
            "   Prediction: Human (Confidence: 1.000)\n",
            "\n",
            "  Probabilities: Human: 1.000, AI: 0.000\n",
            "\n",
            "3. Text: Thats a really really good subject, but acctully i have to say that i agree with specializing in one thing, Beacuse if some one did then when he well give 100% to making his catagory the best and making his job the best. Like if we had a cardiac doctor if you asked him he well tell you that he is trying to be the best and to invent a new methods to fix the heart. so, At the end of the road if he was ambesiuos he can do it . all am saying that its better to specialize in on subject.one, its better to improve that subject.two, it well be better for him not to be puzzled.and three,it well make him the best in that subject. however, i think the its good to have a broad knowledge but while foucsing on one major. like some one is an engeneering but at the same time he can creat other bussnis away from his major,like he could work at the stocks or open a store to sell any thing.but, there is some thing verey importanat. that this other work well not effect his major work beacuse in this way he will be a loser in both subjects. anyway my point is that both of them is good.but, for some people that is good for others the other one is better. and as the old sayin\"defers in opinun will not destroy the case\".but i said mine and thank you for this verey good subject and thatsall i have to say.\n",
            "\n",
            "   Prediction: Human (Confidence: 0.996)\n",
            "\n",
            "  Probabilities: Human: 0.996, AI: 0.004\n",
            "\n",
            "4. Text: I disagree with the statement saying that it is better to have broad knowledge of many subjects rather than specializing in one specific subject. I will illustrate my views below.\n",
            "\n",
            "There is an English proverb which beautifully fits in the above case: \"A Jack of all is a master of none.\"\n",
            "In the past scientific knowledge was relatively limited as compared to now. Now many new fields have been developed and even in a single field there are many sub divisions. For e.g. Computers. Before there no sub-divisions in the field of computers but now we can broadly classify them as Hardware, software, Middle-ware, Internet & Networking, etc.\n",
            "Even in these sub-divisions we can have several more options.\n",
            "The point I am trying to make here is that fields are more diverse and varied then they were before. Hence it is simply not possible to excel in all of them and having only a general idea about them will not suffice.\n",
            "\n",
            "Additionally knowledge has become more and more complex than before. Having a general idea about things is not enough to perform the tasks adequately. For e.g. A CFO (Chief Financial Officer) of a company has reasonable knowledge about Law. So does it mean that he will be as competent as a Lawyer specialising in these tasks? Alternatively a lawyer cannot do adequate justice to the job of a CFO.\n",
            "\n",
            "Let me illustrate my point further. Would you like to live in a building which has been made by person having a \"general\" idea of construction, architecture and engineering or would prefer living in a building made by a team of experts in their respective fields. Focus on one topic inspires confidence not only in others but also in the person doing the job. \n",
            "\n",
            "Hence with the points above I have best tried to justify my conclusion.\n",
            "\n",
            "   Prediction: Human (Confidence: 0.988)\n",
            "\n",
            "  Probabilities: Human: 0.988, AI: 0.012\n",
            "\n",
            "5. Text: It is undeniable that advertisements play a significant role in shaping consumer perceptions and influencing purchasing decisions. While some advertisements may accurately portray products, I strongly agree that most advertisements tend to exaggerate the benefits and qualities of products, making them seem far better than they truly are. This tendency is driven by the inherent goal of advertising: to persuade consumers to buy. \n",
            "\n",
            "One common tactic employed by advertisers is the use of selective information and misleading claims. For instance, a commercial for a weight-loss product might showcase individuals who have achieved dramatic results, while conveniently omitting the fact that these individuals may have also undergone rigorous exercise regimes and dietary changes. This selective presentation creates a false impression of the product's effectiveness. \n",
            "\n",
            "Furthermore, advertisements often rely heavily on emotional appeals and visual imagery to evoke positive associations with the product. A car commercial might feature a sleek, luxurious car driving through scenic landscapes, implying that owning the car will bring happiness and freedom. However, the reality is that the car itself does not guarantee these feelings. \n",
            "\n",
            "In conclusion, while some advertisements may be informative and truthful, the majority tend to embellish the qualities of products to create a more appealing image. By selectively presenting information, using emotional appeals, and employing visual trickery, advertisers aim to persuade consumers to buy products that may not live up to their exaggerated promises. It is crucial for consumers to be aware of these tactics and to critically evaluate advertising messages before making purchasing decisions.\n",
            "\n",
            "   Prediction: AI (Confidence: 0.752)\n",
            "\n",
            "  Probabilities: Human: 0.248, AI: 0.752\n",
            "\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compareing all Models Side by Side\n",
        "# ========================================\n",
        "\n",
        "if svm_available and (dt_available and ada_available):\n",
        "    print(\"COMPARING All MODELS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    agreements = 0\n",
        "    disagreements = 0\n",
        "\n",
        "    for i, text in enumerate(test_essay, 1):\n",
        "        print(f\"{i}. Text: {text}\")\n",
        "\n",
        "        # Test Decision Trees\n",
        "        dt_prediction = loaded_dt_classifier.predict(X_test)[0]\n",
        "        dt_probability = loaded_dt_classifier.predict_proba(X_test)[0]\n",
        "        dt_classification = \"Human\" if dt_prediction == 0 else \"AI\"\n",
        "        dt_confidence = max(dt_probability)\n",
        "\n",
        "        # Test SVM\n",
        "        if svm_available:\n",
        "            svm_prediction = loaded_pipeline_svm.predict([text])[0]\n",
        "            svm_probability = loaded_pipeline_svm.predict_proba([text])[0]\n",
        "\n",
        "        svm_classification = \"Human\" if svm_prediction == 0 else \"AI\"\n",
        "        svm_confidence = max(svm_probability)\n",
        "\n",
        "        # Test AdaBoost\n",
        "        if ada_available:\n",
        "            ada_prediction = loaded_pipeline_svm.predict([text])[0]\n",
        "            ada_probability = loaded_pipeline_svm.predict_proba([text])[0]\n",
        "        ada_classification = \"Human\" if ada_prediction == 0 else \"AI\"\n",
        "        ada_confidence = max(ada_probability)\n",
        "\n",
        "\n",
        "        print(f\"   Decision Tree: {dt_classification} (Confidence: {dt_confidence:.3f})\")\n",
        "        print(f\"   SVM:   {svm_classification} (Confidence: {dt_confidence:.3f})\")\n",
        "        print(f\"   ADaBoost: {dt_classification} (Confidence: {dt_confidence:.3f})\")\n",
        "\n",
        "\n",
        "        # Show agreement/disagreement\n",
        "        if dt_classification == svm_classification == ada_classification:\n",
        "            print(f\"   Agreement:All models agree on {svm_classification}\")\n",
        "            agreements += 1\n",
        "        else:\n",
        "            print(f\"   Disagreement: SVM: {svm_classification}, DT: {dt_classification}, ADA: {ada_classification}\")\n",
        "            disagreements += 1\n",
        "\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOVDXTJRX-1T",
        "outputId": "c59c82a3-229a-4b3c-aba4-35a7b82e1462"
      },
      "id": "AOVDXTJRX-1T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPARING All MODELS\n",
            "======================================================================\n",
            "1. Text: Enjoyment means entertainment, satisfaction of one's soul and containment with the happenings in life. I would like to disagree with this statement. This is because entertainment would mean differently to different people. Entertainment depends on various factors like the person's attitude and his notion or perspective on entertainment.\n",
            "   The younger generation tends to enjoy themselves by going to parties, meeting new people, making new friends and going for long drives. The way a youngster enjoys himself or herself depends on the attitude and nature of the individual. Some people might like to go to parties for entertainment while others might like to watch a movie.\n",
            "   On the other hand the older people might also do the same things that youngsters do or they may engage in activities considered as dull and boring by the youngsters. I would like to take examples of two famous personalities here who despite their age never complained of boredom. Firstly, I would like to take the example of Mother Teresa who despite her old age found enjoyment in playing with children and serving the needy. Secondly, I would like to take the example of the famous painter, M.F. Hussain. M.F. Hussain is more than eighty years old but finds enjoyment in his paintings. He likes to draw and finds his entertainment in his drawings. \n",
            "   We can find people both among younsters and aged who remain depressed and do not tend to enjoy themselves. They lead the life of a loner and stay in recluse. The youngsters have a pressure to make their life which may in turn have an effect on the way they tend to enjoy themselves. But this might not be the case with the older people. They have a life, they have attained their goals and can live a peaceful life which in itself is an enjoyment.The old people also tend to enjoy themselves by talking to others of their age and about their life's experiences.\n",
            "    Thus we see that the entire concept of enjoyment differs from one person to other. We can never say with surity that youngsters tend to enjoy more than the old people. Everything depends on the nature and the attitude of people. If somebody wants to enjoy age is never a deciding factor. It's the perspective and the likes and dislikes of a person which tends to decide how well the person is enjoying his life.\n",
            "   Decision Tree: Human (Confidence: 0.962)\n",
            "   SVM:   Human (Confidence: 0.962)\n",
            "   ADaBoost: Human (Confidence: 0.962)\n",
            "   Agreement:All models agree on Human\n",
            "\n",
            "2. Text: Before to start with my opinion of the topic i must to say that in this life what is the much important thing of a product? So if we want to responde about this question we can tell that the image of a product it's very important but it's only a vision fact. So I agree with the topic.\n",
            "\n",
            "The advertisements make products seem a good image, so the people are involved to buy these. They show us the best quality of products and not the reality. An example is if you want buy a car you see that this car is the best for speed, or elegance, or horse power, or other characterists but you don't see what is the consume, if the power of this car is economicaly good. \n",
            "\n",
            "But the advertisments are in all our life, becouse if you watch TV shows or programs there are many break of advertisements, if you read a newspaper there are pages and pages of advertisements, when you go to work or only you go out in the streets you can see more and more advertisements. So they are a subliminar message. And the power of its is that can seem products better than really are.\n",
            "     \n",
            "However, the advertisements are most important for the economy because a good advertisements can make some profit for the industries. But the buyers have one thing from their side, that the product is much far from reality they can't buy it. \n",
            "\n",
            "In conclusion I'm in accord at the topic but i tell to all the people of the world that not are impressionate for the apperance of an advertisement but see the really quality of products, that we can change something in the world.\n",
            "   Decision Tree: Human (Confidence: 0.962)\n",
            "   SVM:   Human (Confidence: 0.962)\n",
            "   ADaBoost: Human (Confidence: 0.962)\n",
            "   Agreement:All models agree on Human\n",
            "\n",
            "3. Text: Thats a really really good subject, but acctully i have to say that i agree with specializing in one thing, Beacuse if some one did then when he well give 100% to making his catagory the best and making his job the best. Like if we had a cardiac doctor if you asked him he well tell you that he is trying to be the best and to invent a new methods to fix the heart. so, At the end of the road if he was ambesiuos he can do it . all am saying that its better to specialize in on subject.one, its better to improve that subject.two, it well be better for him not to be puzzled.and three,it well make him the best in that subject. however, i think the its good to have a broad knowledge but while foucsing on one major. like some one is an engeneering but at the same time he can creat other bussnis away from his major,like he could work at the stocks or open a store to sell any thing.but, there is some thing verey importanat. that this other work well not effect his major work beacuse in this way he will be a loser in both subjects. anyway my point is that both of them is good.but, for some people that is good for others the other one is better. and as the old sayin\"defers in opinun will not destroy the case\".but i said mine and thank you for this verey good subject and thatsall i have to say.\n",
            "   Decision Tree: Human (Confidence: 0.962)\n",
            "   SVM:   Human (Confidence: 0.962)\n",
            "   ADaBoost: Human (Confidence: 0.962)\n",
            "   Agreement:All models agree on Human\n",
            "\n",
            "4. Text: I disagree with the statement saying that it is better to have broad knowledge of many subjects rather than specializing in one specific subject. I will illustrate my views below.\n",
            "\n",
            "There is an English proverb which beautifully fits in the above case: \"A Jack of all is a master of none.\"\n",
            "In the past scientific knowledge was relatively limited as compared to now. Now many new fields have been developed and even in a single field there are many sub divisions. For e.g. Computers. Before there no sub-divisions in the field of computers but now we can broadly classify them as Hardware, software, Middle-ware, Internet & Networking, etc.\n",
            "Even in these sub-divisions we can have several more options.\n",
            "The point I am trying to make here is that fields are more diverse and varied then they were before. Hence it is simply not possible to excel in all of them and having only a general idea about them will not suffice.\n",
            "\n",
            "Additionally knowledge has become more and more complex than before. Having a general idea about things is not enough to perform the tasks adequately. For e.g. A CFO (Chief Financial Officer) of a company has reasonable knowledge about Law. So does it mean that he will be as competent as a Lawyer specialising in these tasks? Alternatively a lawyer cannot do adequate justice to the job of a CFO.\n",
            "\n",
            "Let me illustrate my point further. Would you like to live in a building which has been made by person having a \"general\" idea of construction, architecture and engineering or would prefer living in a building made by a team of experts in their respective fields. Focus on one topic inspires confidence not only in others but also in the person doing the job. \n",
            "\n",
            "Hence with the points above I have best tried to justify my conclusion.\n",
            "   Decision Tree: Human (Confidence: 0.962)\n",
            "   SVM:   Human (Confidence: 0.962)\n",
            "   ADaBoost: Human (Confidence: 0.962)\n",
            "   Agreement:All models agree on Human\n",
            "\n",
            "5. Text: It is undeniable that advertisements play a significant role in shaping consumer perceptions and influencing purchasing decisions. While some advertisements may accurately portray products, I strongly agree that most advertisements tend to exaggerate the benefits and qualities of products, making them seem far better than they truly are. This tendency is driven by the inherent goal of advertising: to persuade consumers to buy. \n",
            "\n",
            "One common tactic employed by advertisers is the use of selective information and misleading claims. For instance, a commercial for a weight-loss product might showcase individuals who have achieved dramatic results, while conveniently omitting the fact that these individuals may have also undergone rigorous exercise regimes and dietary changes. This selective presentation creates a false impression of the product's effectiveness. \n",
            "\n",
            "Furthermore, advertisements often rely heavily on emotional appeals and visual imagery to evoke positive associations with the product. A car commercial might feature a sleek, luxurious car driving through scenic landscapes, implying that owning the car will bring happiness and freedom. However, the reality is that the car itself does not guarantee these feelings. \n",
            "\n",
            "In conclusion, while some advertisements may be informative and truthful, the majority tend to embellish the qualities of products to create a more appealing image. By selectively presenting information, using emotional appeals, and employing visual trickery, advertisers aim to persuade consumers to buy products that may not live up to their exaggerated promises. It is crucial for consumers to be aware of these tactics and to critically evaluate advertising messages before making purchasing decisions.\n",
            "   Decision Tree: Human (Confidence: 0.962)\n",
            "   SVM:   AI (Confidence: 0.962)\n",
            "   ADaBoost: Human (Confidence: 0.962)\n",
            "   Disagreement: SVM: AI, DT: Human, ADA: AI\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "total_tests = len(test_essay)\n",
        "agreement_rate = (agreements / total_tests) * 100\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total tests: {total_tests}\")\n",
        "print(f\"Agreements: {agreements}\")\n",
        "print(f\"Disagreements: {disagreements}\")\n",
        "print(f\"Agreement rate: {agreement_rate:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Kor7FDYGMi",
        "outputId": "09af636d-e506-4498-e85c-eb0a655b5678"
      },
      "id": "w4Kor7FDYGMi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MODEL COMPARISON SUMMARY\n",
            "======================================================================\n",
            "Total tests: 5\n",
            "Agreements: 4\n",
            "Disagreements: 1\n",
            "Agreement rate: 80.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary and Status\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL TESTING COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nFor Streamlit deployment:\")\n",
        "print(\"üîπ Same TF-IDF vectorizer for both models\")\n",
        "print(\"üîπ Switch between SVM, DT and AdaBoost classifiers\")\n",
        "print(\"üîπ Compare predictions from all models\")\n",
        "print(\"üîπ Show agreement/disagreement analysis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IOVB97DYU1R",
        "outputId": "08ffc726-365b-4b6d-9e43-fb1677eef762"
      },
      "id": "7IOVB97DYU1R",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "MODEL TESTING COMPLETED!\n",
            "============================================================\n",
            "\n",
            "For Streamlit deployment:\n",
            "üîπ Same TF-IDF vectorizer for both models\n",
            "üîπ Switch between SVM, DT and AdaBoost classifiers\n",
            "üîπ Compare predictions from all models\n",
            "üîπ Show agreement/disagreement analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Model Summary by comparing all models\n",
        "\n",
        "print(\"MODEL SUMMARY FOR DEPLOYMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"Best performing model: {svm_best_pipeline}\")\n",
        "print(f\"Final accuracy: {pipeline_accuracy:.4f}\")\n",
        "print(f\"Cross-validation score: {svm_cv_scores.mean():.4f} (+/- {svm_cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "print(f\"\\nTraining data statistics:\")\n",
        "print(f\"- Total samples: {len(X)}\")\n",
        "print(f\"- Human samples: {sum(y)}\")\n",
        "print(f\"- AI samples: {len(y) - sum(y)}\")\n",
        "\n",
        "print(f\"\\nModel features:\")\n",
        "print(f\"- Text preprocessing: Advanced with lemmatization\")\n",
        "print(f\"- Vectorization: TF-IDF with {tfidf_vectorizer.max_features} features\")\n",
        "print(f\"- Algorithm: {svm_best_pipeline}\")\n",
        "\n",
        "print(f\"\\nFiles created for Streamlit deployment:\")\n",
        "print(f\"1. {pipeline_filename} - Complete ML pipeline\")\n",
        "print(f\"2. {tfidf_filename} - TF-IDF vectorizer\")\n",
        "\n",
        "print(f\"\\nNext steps:\")\n",
        "print(\"1. Downloaded the .pkl files from Colab\")\n",
        "print(\"2. We will use them in our Streamlit application\")\n",
        "print(\"3. The pipeline can process raw text and make predictions\")\n",
        "\n",
        "print(\"\\Our ML models are ready for deployment!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGJ8JhwTxfCn",
        "outputId": "567497e8-a293-441e-c0a9-54f60746a695"
      },
      "id": "fGJ8JhwTxfCn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL SUMMARY FOR DEPLOYMENT\n",
            "==================================================\n",
            "Best performing model: Pipeline(steps=[('vectorizer',\n",
            "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 3))),\n",
            "                ('classifier',\n",
            "                 SVC(C=10, kernel='linear', probability=True,\n",
            "                     random_state=42))])\n",
            "Final accuracy: 0.9692\n",
            "Cross-validation score: 0.9732 (+/- 0.0138)\n",
            "\n",
            "Training data statistics:\n",
            "- Total samples: 3728\n",
            "- Human samples: 1864\n",
            "- AI samples: 1864\n",
            "\n",
            "Model features:\n",
            "- Text preprocessing: Advanced with lemmatization\n",
            "- Vectorization: TF-IDF with 5000 features\n",
            "- Algorithm: Pipeline(steps=[('vectorizer',\n",
            "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 3))),\n",
            "                ('classifier',\n",
            "                 SVC(C=10, kernel='linear', probability=True,\n",
            "                     random_state=42))])\n",
            "\n",
            "Files created for Streamlit deployment:\n",
            "1. human_ai_pipeline.pkl - Complete ML pipeline\n",
            "2. tfidf_vectorizer.pkl - TF-IDF vectorizer\n",
            "\n",
            "Next steps:\n",
            "1. Downloaded the .pkl files from Colab\n",
            "2. We will use them in our Streamlit application\n",
            "3. The pipeline can process raw text and make predictions\n",
            "\\Our ML models are ready for deployment!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 18.393171,
      "end_time": "2023-02-16T22:13:02.202180",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-02-16T22:12:43.809009",
      "version": "2.3.4"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}